# ü§ñ RAG-SCADA-Chat üí¨

Este proyecto implementa un sistema de **Generaci√≥n Aumentada por Recuperaci√≥n (RAG)** utilizando **Modelos de Lenguaje Grande (LLMs)** para transformar manuales t√©cnicos en PDF (operaci√≥n y mantenimiento de sistemas SCADA el√©ctricos) en una base de conocimiento conversacional y accesible. Su objetivo es proporcionar **respuestas instant√°neas, coherentes y exactas** a las consultas de los usuarios, reduciendo significativamente el tiempo de acceso y rastreo de informaci√≥n en la documentaci√≥n tradicional.

## üìå Caso de Uso e Impacto

En la **industria de transmisi√≥n y generaci√≥n el√©ctrica**, el acceso r√°pido a la informaci√≥n de los manuales de operaci√≥n y mantenimiento de sistemas SCADA es crucial. La dificultad de rastrear datos espec√≠ficos en extensos archivos PDF se elimina al sistematizar esta documentaci√≥n como una **Base de Conocimiento** a la que se accede mediante un chat inteligente.

El sistema se enfoca en manuales de **SCADA para el control y supervisi√≥n de sistemas el√©ctricos**, ofreciendo:

  * **Acceso Instant√°neo:** Consultas a trav√©s de un chat en lugar de b√∫squeda manual en PDFs.
  * **Informaci√≥n Espec√≠fica:** Respuestas directas, coherentes y exactas potenciadas por LLMs.
  * **Eficiencia Operacional:** Ahorro de tiempo significativo para personal de mantenimiento y operaci√≥n.

-----

## ‚öôÔ∏è Arquitectura del Proyecto y Microservicios

El proyecto est√° dise√±ado como una aplicaci√≥n de microservicios contenerizada con **Docker**, asegurando escalabilidad y f√°cil despliegue.

| Servicio | Tecnolog√≠a | Descripci√≥n de Funcionalidad Principal |
| :--- | :--- | :--- |
| **`rag-core`** | `FastAPI`, `Langchain` | **N√∫cleo del Backend.** Gestiona la ingesta de documentos, el procesamiento RAG (reescritura, b√∫squeda h√≠brida, reranking, consulta a LLM) y la transferencia de respuestas. |
| **`airflow`** | `Airflow` (DAGs) | **Orquestaci√≥n de Ingesta.** Programa semanalmente la b√∫squeda y procesamiento pesado de nuevos PDFs. |
| **`frontend`** | `Streamlit` | **Interfaz de Usuario (UI).** Permite a los usuarios realizar consultas, visualizar respuestas y enviar evaluaciones (feedback). |
| **`postgres_app`** | `PostgreSQL` | **Base de Datos de Aplicaci√≥n.** Almacena metadatos de documentos (hash) y el feedback/evaluaci√≥n del usuario. |
| **`postgres`** | `PostgreSQL` | **Base de Datos de Airflow.** Almacena la metadata de la orquestaci√≥n de Airflow. |
| **`qdrant`** | `Qdrant` | **Base de Datos Vectorial.** Almacena los *retrieval_context* sem√°nticos y sus vectores para la recuperaci√≥n RAG. |

-----

## üíª Flujo de Trabajo y Funcionalidad (RAG & Ingesta)

El sistema opera bajo dos flujos principales: la **Ingesta de Documentos (v√≠a Airflow)** y la **Consulta del Usuario (v√≠a Frontend)**.

### 1\. Flujo de Ingesta (Airflow Orquestado)

Este proceso se ejecuta mediante un **DAG programado semanalmente** para mantener la Base de Conocimiento actualizada:

1.  **B√∫squeda y Verificaci√≥n:** `airflow` se conecta a `rag-core` para buscar nuevos PDFs en las carpetas de origen.
2.  `rag-core` utiliza **hashes** para verificar si un documento ya fue procesado y genera una lista de pendientes.
3.  **Procesamiento Pesado:** Si hay documentos pendientes, `airflow` desencadena el proceso en `rag-core`.
      * **Limpieza y Estructuraci√≥n** de los PDFs.
      * **Creaci√≥n de *retrieval_context* Sem√°nticos** (fragmentos de texto).
      * **Almacenamiento en BBDD:** Los *retrieval_context* y vectores se guardan en **`qdrant`**.
      * **Almacenamiento de Metadatos:** El hash del documento y otros metadatos se guardan en **`postgres_app`**.

### 2\. Flujo de Consulta (Tiempo Real)

1.  **Consulta de Usuario:** El usuario ingresa una pregunta en la interfaz web de **`frontend`** (`Streamlit`).
2.  **Procesamiento en `rag-core`:**
      * **Reescritura de *Query*:** Mejora la consulta inicial para optimizar la b√∫squeda.
      * **B√∫squeda H√≠brida:** Recupera *retrieval_context* relevantes de **`qdrant`**.
      * ***Reranker*:** Selecciona los *retrieval_context* m√°s significativos.
      * **Generaci√≥n de Respuesta:** La *query* optimizada y los *retrieval_context* seleccionados se pasan al **LLM**.
3.  **Respuesta al Usuario:** `rag-core` env√≠a la respuesta del LLM al `frontend`, incluyendo: el texto de la respuesta, el *score* de relevancia, el resultado del *reranker*, el ID del *chunk* y el texto del *chunk* utilizado.
4.  **Feedback del Usuario:** El usuario puede enviar una evaluaci√≥n. El `frontend` tramita esta evaluaci√≥n, y **`rag-core`** la almacena en **`postgres_app`**.

-----

## ‚ú® Caracter√≠sticas Destacadas

  * **Multilenguaje:** Capacidad para **distinguir el idioma** de la consulta y entregar la respuesta en el mismo idioma (**probado en Ingl√©s y Espa√±ol**).
  * **Evaluaci√≥n y Calidad (Deepeval):** Incluye capacidades para realizar **evaluaci√≥n RAG y LLM** utilizando la librer√≠a `deepeval`, asegurando la **coherencia y exactitud** de las respuestas.
  * **Trazabilidad:** La respuesta incluye metadatos (ID de *chunk*, texto de *chunk*) que permiten al usuario y al sistema rastrear la fuente de la informaci√≥n.

-----

## üõ†Ô∏è Tecnolog√≠as Utilizadas

Las siguientes tecnolog√≠as son la base de este proyecto de microservicios:

  * **Backend:** `FastAPI`
  * **Orquestaci√≥n:** `Airflow`
  * **Frontend:** `Streamlit`
  * **BBDD Vectorial:** `Qdrant`
  * **BBDD Relacional:** `PostgreSQL`
  * **Framework RAG:** `LangChain`
  * **Embeddings:** `FastEmbed`
  * **Contenerizaci√≥n:** `Docker`
  * **Evaluaci√≥n:** `Deepeval`

-----

## üöÄ Despliegue (Pr√≥ximamente)

*(En esta secci√≥n se incluir√≠an los comandos de Docker/Docker Compose una vez que est√©n definidos, por ejemplo:)*

```bash
# 1. Clonar el repositorio
git clone <URL_DEL_REPOSITORIO>
cd RAG-SCADA-Chat

# 2. Levantar los microservicios con Docker Compose
docker-compose up -d --build
```

**Acceso:**

  * **Frontend (Streamlit):** `http://localhost:8501`
  * **Airflow UI:** `http://localhost:8080`
  * **FastAPI Docs (rag-core):** `http://localhost:8000/docs`

  ---
  ## Nuevo readme (verificar)

  ¬°Excelente\! La informaci√≥n sobre el proceso de instalaci√≥n, el manejo de la base de conocimiento inicial, el *trigger* manual y el archivo de preguntas (`preguntas.json`) son cruciales.

He actualizado la estructura del `README.md` propuesta, a√±adiendo una secci√≥n detallada de **Instalaci√≥n y Despliegue** con los pasos que has indicado, y he agregado las secciones recomendadas de **Contacto** y **Licencia**.

-----

# ü§ñ RAG-SCADA-Chat üí¨

Este proyecto implementa un sistema de **Generaci√≥n Aumentada por Recuperaci√≥n (RAG)** utilizando **Modelos de Lenguaje Grande (LLMs)** para transformar manuales t√©cnicos en PDF (operaci√≥n y mantenimiento de sistemas SCADA el√©ctricos) en una base de conocimiento conversacional y accesible. Su objetivo es proporcionar **respuestas instant√°neas, coherentes y exactas** a las consultas de los usuarios, reduciendo significativamente el tiempo de acceso y rastreo de informaci√≥n en la documentaci√≥n tradicional.

-----

## üìå Caso de Uso e Impacto

En la **industria de transmisi√≥n y generaci√≥n el√©ctrica**, el acceso r√°pido a la informaci√≥n de los manuales de operaci√≥n y mantenimiento de sistemas SCADA es crucial. La dificultad de rastrear datos espec√≠ficos en extensos archivos PDF se elimina al sistematizar esta documentaci√≥n como una **Base de Conocimiento** a la que se accede mediante un chat inteligente.

El sistema se enfoca en manuales de **SCADA para el control y supervisi√≥n de sistemas el√©ctricos**, ofreciendo:

  * **Acceso Instant√°neo:** Consultas a trav√©s de un chat en lugar de b√∫squeda manual en PDFs.
  * **Informaci√≥n Espec√≠fica:** Respuestas directas, coherentes y exactas potenciadas por LLMs.
  * **Eficiencia Operacional:** Ahorro de tiempo significativo para personal de mantenimiento y operaci√≥n.

-----

## ‚öôÔ∏è Arquitectura del Proyecto y Microservicios

El proyecto est√° dise√±ado como una aplicaci√≥n de microservicios contenerizada con **Docker**, asegurando escalabilidad y f√°cil despliegue.

| Servicio | Tecnolog√≠a | Descripci√≥n de Funcionalidad Principal |
| :--- | :--- | :--- |
| **`rag-core`** | `FastAPI`, `Langchain` | **N√∫cleo del Backend.** Gestiona la ingesta de documentos, el procesamiento RAG (reescritura, b√∫squeda h√≠brida, reranking, consulta a LLM) y la transferencia de respuestas. |
| **`airflow`** | `Airflow` (DAGs) | **Orquestaci√≥n de Ingesta.** Programa semanalmente la b√∫squeda y procesamiento pesado de nuevos PDFs. |
| **`frontend`** | `Streamlit` | **Interfaz de Usuario (UI).** Permite a los usuarios realizar consultas, visualizar respuestas y enviar evaluaciones (feedback). |
| **`postgres_app`** | `PostgreSQL` | **Base de Datos de Aplicaci√≥n.** Almacena metadatos de documentos (hash) y el feedback/evaluaci√≥n del usuario. |
| **`postgres`** | `PostgreSQL` | **Base de Datos de Airflow.** Almacena la metadata de la orquestaci√≥n de Airflow. |
| **`qdrant`** | `Qdrant` | **Base de Datos Vectorial.** Almacena los *retrieval_context* sem√°nticos y sus vectores para la recuperaci√≥n RAG. |

-----

## üöÄ Instalaci√≥n y Despliegue

Sigue los siguientes pasos para levantar la aplicaci√≥n y procesar la base de conocimiento inicial:

### 1\. Requisitos Previos

Aseg√∫rate de tener instalado:

  * **Docker**
  * **Docker Compose**

### 2\. Pasos de Despliegue

1.  **Clonar el Repositorio:**

    ```bash
    git clone <URL_DEL_REPOSITORIO>
    cd RAG-SCADA-Chat
    ```

2.  **Configurar Variables de Entorno:**

      * Copia el archivo de ejemplo y reconf√≠guralo:
        ```bash
        cp .env.example .env
        ```
      * **Edita el archivo `.env`** para completar las variables necesarias (puertos, credenciales de bases de datos, claves de APIs si son requeridas por los LLMs, etc.).

3.  **Levantar los Microservicios:**

    ```bash
    docker-compose up -d --build
    ```

    Esto inicializar√° todos los servicios (FastAPI, Airflow, Streamlit, Qdrant y PostgreSQL).

### 3\. Carga de Base de Conocimiento Inicial

Para que la aplicaci√≥n funcione, es necesario cargar los manuales PDF en la carpeta que el servicio `rag-core` monitorea.

1.  **Mover Archivos PDF:**

      * Copia los archivos PDF de la carpeta `Manuales pdfs` a la ruta interna de `rag-core`:
        ```bash
        cp Manuales\ pdfs/* service/rag-core/data/raw/
        ```
      * **Nota de Procesamiento:** Mover **todos** los manuales puede requerir hasta **90 minutos (1 hora y 30 minutos)** en equipos con recursos limitados. Para una prueba inicial r√°pida, se recomienda mover solo **1 o 2 manuales**.

2.  **Lanzar el *Trigger* de Ingesta:**

      * Una vez que los archivos est√°n en la carpeta, dir√≠gete a la interfaz web de Airflow: `http://localhost:8080`.
      * Inicia sesi√≥n con las credenciales configuradas en el `.env`.
      * Busca el DAG llamado **`scada_rag_ingestion_dag`** y l√°nzalo manualmente (*trigger*).
      * Este proceso se conectar√° con `rag-core` para iniciar la limpieza, *chunking* y almacenamiento vectorial en **Qdrant**.

### 4\. Consultas y Evaluaci√≥n

1.  **Acceder al Frontend:** Una vez completado el procesamiento del DAG, accede a la interfaz de chat: `http://localhost:8501`.
2.  **Realizar Consultas:** Utiliza el chat para realizar preguntas sobre el contenido de los manuales procesados.
3.  **Preguntas de Referencia:** El archivo **`preguntas.json`** contiene un set de preguntas formuladas por un experto en SCADA SDM. Utiliza estas preguntas como referencia para:
      * Verificar las respuestas esperadas.
      * Ejecutar los *scripts* de **Deepeval** para la evaluaci√≥n de la calidad RAG y LLM.

-----

## ‚ú® Caracter√≠sticas Destacadas

  * **Multilenguaje:** Capacidad para **distinguir el idioma** de la consulta y entregar la respuesta en el mismo idioma (**probado en Ingl√©s y Espa√±ol**).
  * **Evaluaci√≥n y Calidad (Deepeval):** Incluye capacidades para realizar **evaluaci√≥n RAG y LLM** utilizando la librer√≠a `deepeval`, asegurando la **coherencia y exactitud** de las respuestas.
  * **Trazabilidad:** La respuesta incluye metadatos (ID de *chunk*, texto de *chunk*) que permiten al usuario y al sistema rastrear la fuente de la informaci√≥n.

-----

## üõ†Ô∏è Tecnolog√≠as Utilizadas

`Postgres`, `Qdrant`, `Airflow`, `Streamlit`, `FastAPI`, `LangChain`, `FastEmbed`, `Docker`, `Deepeval`.

-----

## üìû Contacto

Si tienes preguntas, sugerencias o quieres colaborar con el proyecto, puedes contactar al desarrollador principal a trav√©s de:

  * **Nombre:** Carlos Villarreal P.
  * **Correo Electr√≥nico:** `villarreal.fx@gmail.com`
  * **LinkedIn:** `[Tu Perfil de LinkedIn]`

-----

## üìú Licencia

Este proyecto est√° bajo la Licencia **[Indica el tipo de licencia, e.g., MIT, Apache 2.0]**. Consulta el archivo `LICENSE` para m√°s detalles.

***

## üî¨ Gu√≠a de Uso y Demostraci√≥n

Para una demostraci√≥n visual y un recorrido paso a paso sobre c√≥mo usar la aplicaci√≥n, desde el lanzamiento del *trigger* de Airflow hasta la realizaci√≥n de consultas en el *frontend* y la evaluaci√≥n RAG, consulta nuestro tutorial detallado:

‚û°Ô∏è **[TUTORIAL COMPLETO DE USO Y VALIDACI√ìN](TUTORIAL.md)**

En el tutorial encontrar√°s:
* Capturas de pantalla del *trigger* manual de Airflow.
* Ejemplos de consultas utilizando las preguntas de `preguntas.json`.
* C√≥mo se visualiza el *feedback* y la trazabilidad de los *retrieval_context* en la interfaz de usuario.


---

## Qwen

# Sistema de Consulta de Manuales T√©cnicos basado en RAG

## √çndice

- [Descripci√≥n General](#descripci√≥n-general)
- [Arquitectura del Proyecto](#arquitectura-del-proyecto)
  - [Servicio `rag-core`](#servicio-rag-core)
  - [Servicio `airflow`](#servicio-airflow)
  - [Servicio `frontend`](#servicio-frontend)
  - [Servicio `postgres`](#servicio-postgres)
  - [Servicio `postgres_app`](#servicio-postgres_app)
  - [Servicio `qdrant`](#servicio-qdrant)
- [Tecnolog√≠as Utilizadas](#tecnolog√≠as-utilizadas)
- [Caracter√≠sticas Especiales](#caracter√≠sticas-especiales)
- [Instalaci√≥n](#instalaci√≥n)
- [Uso](#uso)
- [Evaluaci√≥n del Sistema](#evaluaci√≥n-del-sistema)
- [Contribuciones](#contribuciones)
- [Licencia](#licencia)

---

## Descripci√≥n General

Este proyecto aborda el desaf√≠o de acceder r√°pidamente a la informaci√≥n contenida en manuales de mantenimiento, operaci√≥n y bit√°coras t√©cnicas, com√∫nmente almacenados en archivos PDF, lo que dificulta su consulta eficiente. Utilizando tecnolog√≠as de vanguardia como **RAG (Retrieval-Augmented Generation)** y **Modelos de Lenguaje de Gran Tama√±o (LLMs)**, se sistematiza esta informaci√≥n en una **base de conocimiento** consultable a trav√©s de un **chat interactivo**.

La aplicaci√≥n proporciona respuestas espec√≠ficas, coherentes, exactas e instant√°neas, mejorando significativamente la experiencia del usuario. Se ha aplicado espec√≠ficamente a manuales de operaci√≥n y mantenimiento de un sistema **SCADA** para el control y supervisi√≥n de sistemas el√©ctricos de transmisi√≥n y generaci√≥n.

El sistema est√° construido como una arquitectura de **microservicios** que se ejecutan en contenedores **Docker**. Incluye un proceso de **limpieza y procesamiento de PDFs**, almacenamiento en bases de datos vectoriales y relacionales, y una interfaz web intuitiva.

---

## Arquitectura del Proyecto

El sistema se compone de los siguientes servicios:

### Servicio `rag-core`

Es el **n√∫cleo** de la aplicaci√≥n. Es una **API construida con FastAPI** que maneja toda la l√≥gica de backend:

- **B√∫squeda y verificaci√≥n de documentos**: Busca PDFs en carpetas, verifica si ya han sido procesados usando un hash y mantiene una lista de documentos pendientes.
- **Procesamiento de documentos**: Limpia, estructura, crea *retrieval_context* sem√°nticos y los almacena en la base de datos vectorial (Qdrant).
- **Almacenamiento de metadatos**: Guarda el hash del documento en PostgreSQL.
- **Procesamiento de consultas**: Recibe consultas del frontend, realiza reescritura de la *query*, b√∫squeda h√≠brida en la base de datos vectorial, aplica *reranking*, selecciona los *retrieval_context* m√°s relevantes y los env√≠a junto con la consulta a un LLM.
- **Respuesta del LLM**: Recibe la respuesta del LLM y la transfiere al frontend, incluyendo m√©tricas como *score*, *reranker*, ID del *chunk* y su texto.
- **Evaluaci√≥n del usuario**: Recibe y almacena en PostgreSQL la evaluaci√≥n que el usuario proporciona sobre la respuesta.

### Servicio `airflow`

Orquesta tareas de procesamiento mediante un **DAG programado** (por ejemplo, semanalmente):

- **Sincronizaci√≥n con `rag-core`**: Consulta si hay nuevos documentos para procesar.
- **Procesamiento pesado**: Si existen documentos pendientes, coordina con `rag-core` para iniciar el procesamiento detallado de PDFs.

### Servicio `frontend`

Es la **interfaz web** desarrollada con **Streamlit**:

- **Consulta del usuario**: Presenta una interfaz donde el usuario puede realizar preguntas.
- **Visualizaci√≥n de respuestas**: Muestra la respuesta recibida de `rag-core`.
- **Evaluaci√≥n del usuario**: Permite al usuario evaluar la calidad de la respuesta y enviar esa evaluaci√≥n a `rag-core`.

### Servicio `postgres`

Base de datos **PostgreSQL** dedicada al almacenamiento de metadatos y estado de los **workflows de Airflow**.

### Servicio `postgres_app`

Base de datos **PostgreSQL** dedicada al almacenamiento de **datos de la aplicaci√≥n**, incluyendo **feedback de usuarios**.

### Servicio `qdrant`

**Base de datos vectorial** utilizada para almacenar los *retrieval_context* sem√°nticos y sus representaciones vectoriales, facilitando la recuperaci√≥n eficiente de informaci√≥n relevante.

---

## Tecnolog√≠as Utilizadas

- **FastAPI**: Framework web para la API backend.
- **Streamlit**: Framework para la interfaz web.
- **LangChain**: Framework para trabajar con LLMs y RAG.
- **FastEmbedding**: Para la generaci√≥n de embeddings.
- **Qdrant**: Base de datos vectorial.
- **PostgreSQL**: Base de datos relacional para metadatos y feedback.
- **Apache Airflow**: Orquestador de flujos de trabajo.
- **Docker**: Contenerizaci√≥n de microservicios.
- **DeepEval**: Para la evaluaci√≥n del sistema RAG y LLM.
- **Otras**: Python, etc.

---

## Caracter√≠sticas Especiales

- **Soporte multilenguaje**: El sistema puede detectar el idioma de la consulta (probado en **Ingl√©s** y **Espa√±ol**) y responder en el mismo idioma.
- **Evaluaci√≥n continua**: Integraci√≥n de **DeepEval** para evaluar la calidad del sistema RAG y LLM.
- **Almacenamiento persistente**: Uso de PostgreSQL para metadatos y feedback, y Qdrant para informaci√≥n vectorizada.
- **Automatizaci√≥n**: Procesamiento de nuevos documentos gestionado por un DAG de Airflow.

---

## Instalaci√≥n

1. Clona este repositorio:

   ```bash
   git clone <URL_DEL_REPOSITORIO>
   cd <NOMBRE_DEL_REPOSITORIO>